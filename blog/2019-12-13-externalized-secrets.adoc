= Secrets externalization with Debezium connectors
jpechane
:awestruct-tags: [ secrets, mysql, example ]
:awestruct-layout: blog-post

When a Debezium connector is deployed to a Kafka Connect instance it is sometimes necessary to keep database credentials hidden from cluster API users.

Let's remind how connector registration request looks like for MySQL Debezium connector

[source,json]
----
{
    "name": "inventory-connector",
    "config": {
        "connector.class": "io.debezium.connector.mysql.MySqlConnector",
        "tasks.max": "1",
        "database.hostname": "mysql",
        "database.port": "3306",
        "database.user": "debezium",
        "database.password": "dbz",
        "database.server.id": "184054",
        "database.server.name": "dbserver1",
        "database.whitelist": "inventory",
        "database.history.kafka.bootstrap.servers": "kafka:9092",
        "database.history.kafka.topic": "schema-changes.inventory"
    }
}
----

The `username` and `password` are passed to the cluster as plain strings.
Worse yet anybody who has access to Kafka Connect REST API can issue a `GET` request to obtain a configuration of the connector including the database credentials

```
curl -s http://localhost:8083/connectors/inventory-connector | jq .
```
[source,json]
----
{
  "name": "inventory-connector",
  "config": {
    "connector.class": "io.debezium.connector.mysql.MySqlConnector",
    "database.user": "debezium",
    "database.server.id": "184054",
    "tasks.max": "1",
    "database.hostname": "mysql",
    "database.password": "dbz",
    "database.history.kafka.bootstrap.servers": "kafka:9092",
    "database.history.kafka.topic": "schema-changes.inventory",
    "name": "inventory-connector",
    "database.server.name": "dbserver1",
    "database.whitelist": "inventory",
    "database.port": "3306"
  },
  "tasks": [
    {
      "connector": "inventory-connector",
      "task": 0
    }
  ],
  "type": "source"
}
----

If one Kafka Connect cluster is shared by multiple connectors/teams then this behaviour can be undesiable for security reasons.

To solve the problem the https://cwiki.apache.org/confluence/display/KAFKA/KIP-297%3A+Externalizing+Secrets+for+Connect+Configurations[KIP-297 Externalizing Secrets for Connect Configurations] was implemented since Kafka 2.0.0.

The externalization expects there is at least one implementation class of `org.apache.kafka.common.config.provider.ConfigProvider` interface.
Kafka Connect provides the reference implementation `org.apache.kafka.common.config.provider.FileConfigProvider` that reads secrets from file.
Available config providers are configured at Kafka Connect worker level (e.g. in `connect-distributed.properties`) and are referred to from connector configuration.

An example of worker configuration would be
```
config.providers=file
config.providers.file.class=org.apache.kafka.common.config.provider.FileConfigProvider
```

and the connector registration request will refer to it using
[source,json]
----
{
    "name": "inventory-connector",
    "config": {
        "connector.class": "io.debezium.connector.mysql.MySqlConnector",
        "tasks.max": "1",
        "database.hostname": "mysql",
        "database.port": "3306",
        "database.user": "${file:/secrets/mysql.properties:user}",
        "database.password": "${file:/secrets/mysql.properties:password}",
        "database.server.id": "184054",
        "database.server.name": "dbserver1",
        "database.whitelist": "inventory",
        "database.history.kafka.bootstrap.servers": "kafka:9092",
        "database.history.kafka.topic": "schema-changes.inventory"
    }
}
----

Placeholder `${file:/secrets/mysql.properties:user}` says that `org.apache.kafka.common.config.provider.FileConfigProvider` should be used and this provider will read property file `/secrets/mysql.properties` and extracts property `user` from it to use it.

The file config provider is probably the simplest possible use case and it can be expected that other providers will appear that will integrate with secret repositories or identity management systems.
It should be noted though that file config provider is satisfactory in OpenShift/Kubernetes deployments as `secrets` objects could be injected into cluster pods as files and thus consumed by it.

You can try our https://github.com/debezium/debezium-examples/tree/master/tutorial#using-externalized-secrets[tutorial] demonstrating a deployment of externalized secrets. Please note the two environment variables in Docker Compose `connect` service

```
     - CONNECT_CONFIG_PROVIDERS=file
     - CONNECT_CONFIG_PROVIDERS_FILE_CLASS=org.apache.kafka.common.config.provider.FileConfigProvider
```

These envrionment variables are directly mapped into Kafka Connect worker properties as a functionality of the `debezium/connect` image.

When you issue the REST call to get connector configuration you will see that the sensitive information is externalized and masked from unauthorized persons

```
curl -s http://localhost:8083/connectors/inventory-connector | jq .
```
[source,json]
----
{
  "name": "inventory-connector",
  "config": {
    "connector.class": "io.debezium.connector.mysql.MySqlConnector",
    "database.user": "${file:/secrets/mysql.properties:user}",
    "database.server.id": "184054",
    "tasks.max": "1",
    "database.hostname": "mysql",
    "database.password": "${file:/secrets/mysql.properties:password}",
    "database.history.kafka.bootstrap.servers": "kafka:9092",
    "database.history.kafka.topic": "schema-changes.inventory",
    "name": "inventory-connector",
    "database.server.name": "dbserver1",
    "database.whitelist": "inventory",
    "database.port": "3306"
  },
  "tasks": [
    {
      "connector": "inventory-connector",
      "task": 0
    }
  ],
  "type": "source"
}
----
