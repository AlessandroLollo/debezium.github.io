= CDC Event Flattening
:awestruct-layout: doc
:linkattrs:
:icons: font
:source-highlighter: highlight.js

[NOTE]
====
This SMT is available since Debezium version 0.6.0.
====

[NOTE]
====
This SMT is supported only for SQL database plug-ins, not with MongoDB plug-in.
====

Debezium generates a data change in a form of a complex message structure. The message consists of three parts

* operation and metadata
* the row data before change
* the row data after change

The general message structure for `update` change can look like

[source,json,indent=0]
----
{
	"op": "u",
	"source": {
		...
	}
	"ts_ms": "..."
	"before": {
		"field1", "oldvalue1",
		"field2", "oldvalue2"
	}
	"after": {
		"field1", "newvalue1",
		"field2", "newvalue2"
	}
}
----

More details about the message structure are provided in link:../../connectors[the documentation for each connector].

This format allows the user to get most information about changes happening in the system.
The downside of using the complex format is that other connectors or other parts of Kafka ecosystem usually expects the data in a simple message format that can generally be described like

[source,json,indent=0]
----
{
	"field1", "newvalue1",
	"field2", "newvalue2"
}
----

Debezium provides https://kafka.apache.org/documentation/#connect_transforms[a single message transform] that crosses the bridge between the complex and simple format https://github.com/debezium/debezium/blob/master/debezium-core/src/main/java/io/debezium/transforms/UnwrapFromEnvelope.java[UnwrapFromEnvelope] SMT.

The SMT provides two main functions

* extracts `after` field from examples message and replace the original one with this part
* filters delete and tombstone records according to configuration to tune it according to downstream parts requirements

The SMTs can be applied either on source (Debezium) connector or on sink connector.
We generally recommend to apply the transformation on sink side as it means that the messages stored in Apache Kafka will contain the whole context. The final decision depends on use case for each user.

== Configuration
The configuration is a part of source/sink task connector and is expressed in a set of properties
[source]
----
transforms=unwrap,...
transforms.unwrap.type=io.debezium.transforms.UnwrapFromEnvelope
transforms.unwrap.drop.tombstones=false
----

=== Record filtering for delete records
The SMT provides a special handling for events that signals `delete` operation. When a `DELETE` is executed on a datasource then Debezium generates two records

* record with `d` operation that contains only old row data
* record with `null` value and the same key. This record serves as a tombstone marker for Apache Kafka for https://kafka.apache.org/documentation/#compaction[a log compaction process].

When those two records arrives into the SMT then the SMT turns the `d` record into another tombstone. The user can configure if both record, only one of them or none is filtered out.

[NOTE]
====
SMT by default filters out *BOTH* delete records as the widely used sink connectors like JDBC and ElasticSearch do not support handling of tombstone records.
====

== Configuration options
[cols="35%a,10%a,55%a",width=100,options="header,footer",role="table table-bordered table-striped"] 
|======================= 
|Property 
|Default 
|Description 
 
|`drop.tombstones` 
|`true` 
|SMT removes the tombstone generated by Debezium from the streeam.

|`drop.deletes` 
|`true` 
|SMT removes the `d` record generated by Debezium and converted to tombstone by SMT) from the stream.
|=======================

